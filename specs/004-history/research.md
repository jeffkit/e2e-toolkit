# Research: Test Result Persistence & Trend Analysis

**Feature Branch**: `004-history`
**Date**: 2026-02-26

---

## Decision 1: Storage Engine — better-sqlite3 with WAL Mode

**Rationale**: The spec requires local persistent storage (P1 default), in-memory mode for CI, and future remote-DB expansion. `better-sqlite3` is already identified by the team as the obvious choice. It offers synchronous APIs (ideal for post-test recording where latency is non-critical), zero external server dependencies, and excellent Node.js 20+ / ESM compatibility. WAL (Write-Ahead Logging) mode enables concurrent readers without blocking writes.

**Alternatives considered**:

| Option | Pros | Cons |
|--------|------|------|
| **better-sqlite3 (chosen)** | Synchronous, zero-config, WAL concurrent reads, proven in Node ecosystem | Native addon (prebuilt binaries available), single-writer lock |
| **sql.js (WASM)** | Pure JS, no native addon | 3-5x slower, no WAL support, higher memory |
| **LevelDB / RocksDB** | Fast key-value writes | No SQL, no relational queries for trends |
| **JSON FileStore (existing)** | Already implemented | O(n) queries, no indexing, degrades at scale |

**Trade-offs**: Native addon adds a build step but prebuilt binaries (`prebuild-install`) cover all major platforms. Single-writer is acceptable since test runs are sequential per project; application-level serialization via a write queue handles the edge case of concurrent runs.

**Configuration**:

```typescript
// Optimal PRAGMA settings for this use case
db.pragma('journal_mode = WAL');
db.pragma('synchronous = NORMAL');
db.pragma('busy_timeout = 5000');
db.pragma('temp_store = MEMORY');
db.pragma('cache_size = -8000'); // 8MB cache
```

---

## Decision 2: Schema Migration Strategy — Inline user_version Pragma

**Rationale**: The project is a dev tool (not a multi-tenant SaaS), so migration complexity should be minimal. SQLite's built-in `user_version` pragma provides a zero-dependency migration tracker. Migrations are defined as TypeScript functions in an ordered array and applied in a transaction on database open.

**Alternatives considered**:

| Option | Pros | Cons |
|--------|------|------|
| **user_version pragma (chosen)** | Zero dependencies, atomic, simple | No down-migration (acceptable for dev tool) |
| **@farjs/better-sqlite3-migrate** | Dedicated tool, SQL file based | Extra dependency, build-time bundling |
| **@blackglory/better-sqlite3-migrations** | Up/down support | Extra dependency |
| **sqlite-up** | TypeScript-first, rollback | Extra dependency, overkill for this scope |

**Trade-offs**: No automated rollback. Acceptable because: (1) this is a local dev tool, (2) data is non-critical (can be regenerated by re-running tests), (3) forward-only migrations reduce complexity.

**Pattern**:

```typescript
const MIGRATIONS: Array<(db: Database) => void> = [
  // v1: initial schema
  (db) => {
    db.exec(`CREATE TABLE test_runs (...)`);
    db.exec(`CREATE TABLE test_case_runs (...)`);
  },
  // v2: add indexes (future)
];

function applyMigrations(db: Database): void {
  const currentVersion = db.pragma('user_version', { simple: true });
  for (let i = currentVersion; i < MIGRATIONS.length; i++) {
    db.transaction(() => {
      MIGRATIONS[i]!(db);
      db.pragma(`user_version = ${i + 1}`);
    })();
  }
}
```

---

## Decision 3: Git Context Retrieval — Direct child_process.execSync

**Rationale**: The project already uses `child_process` extensively in `docker-engine.ts`. Adding `simple-git` (14KB) for two commands is unnecessary. `execSync` with `git rev-parse` is reliable, fast (<10ms), and handles error cases (no git, detached HEAD) with a simple try/catch returning `null`.

**Alternatives considered**:

| Option | Pros | Cons |
|--------|------|------|
| **execSync (chosen)** | Zero dependency, consistent with existing patterns | Manual error handling |
| **simple-git** | Rich API, TypeScript types | Unnecessary dependency for 2 commands |
| **git-commit-info** | Dedicated package | Another dependency for trivial task |

**Trade-offs**: Manual error handling for edge cases (no git binary, not a repo, detached HEAD). All handled with try/catch returning `null` per FR-004.

**Implementation**:

```typescript
function getGitContext(cwd: string): { commit: string | null; branch: string | null } {
  try {
    const commit = execSync('git rev-parse HEAD', { cwd, encoding: 'utf-8' }).trim();
    const branch = execSync('git rev-parse --abbrev-ref HEAD', { cwd, encoding: 'utf-8' }).trim();
    return { commit, branch: branch === 'HEAD' ? null : branch };
  } catch {
    return { commit: null, branch: null };
  }
}
```

---

## Decision 4: Configuration Hash — crypto.createHash on YAML Content

**Rationale**: FR-005 requires detecting configuration changes between runs. A SHA-256 hash of the raw `e2e.yaml` file content provides a deterministic, fast fingerprint. Node.js built-in `crypto` module has zero overhead.

**Alternatives considered**:

| Option | Pros | Cons |
|--------|------|------|
| **SHA-256 of file content (chosen)** | Deterministic, fast, zero deps | Whitespace changes trigger new hash |
| **Hash of parsed config object** | Ignores formatting | Non-deterministic JSON.stringify ordering |
| **Hash of specific config fields** | Semantic hashing | Complex, fragile to new fields |

**Trade-offs**: Whitespace-only edits produce a different hash. Acceptable — the intent is to flag "something changed", not "something meaningful changed". The hash is stored for informational/correlation purposes, not for decision-making.

---

## Decision 5: Chart Library — Recharts

**Rationale**: The dashboard already uses React + Vite + Tailwind CSS. Recharts is the best fit for React-native chart integration. For the expected data scale (up to 1000 runs, daily aggregation = ~30-365 data points), both Recharts and Chart.js perform well, but Recharts offers superior React integration (declarative JSX API, responsive containers, composable components) and handles larger datasets more efficiently.

**Alternatives considered**:

| Option | Pros | Cons |
|--------|------|------|
| **Recharts (chosen)** | React-native JSX API, good perf at scale, responsive, active community | ~50KB gzipped |
| **Chart.js + react-chartjs-2** | Smaller bundle (~11KB), canvas-based | Imperative API, less React-idiomatic |
| **Nivo** | Beautiful defaults, D3-based | Larger bundle, more complex API |
| **ECharts** | Feature-rich | Heavy, less React-native |

**Trade-offs**: 50KB vs 11KB bundle size. Acceptable given the dashboard is already a full React app; the DX benefit of Recharts' declarative API outweighs the ~40KB difference.

---

## Decision 6: Flaky Detection Algorithm — Sliding Window Ratio

**Rationale**: The spec defines a clear algorithm (FR-006, FR-007): flaky_score = fail_count / total_runs over the last N runs (default N=10). Five stability levels map to score ranges. This is simple, predictable, and sufficient for the first iteration.

**Alternatives considered**:

| Option | Pros | Cons |
|--------|------|------|
| **Simple ratio (chosen)** | Matches spec exactly, easy to understand and debug | Doesn't weight recency |
| **Exponential weighted average** | Recent failures weighted more | Harder to explain score to users |
| **Bayesian flaky detection** | Statistically robust | Complex, overkill for v1 |

**Trade-offs**: A test that failed 3/10 times long ago has the same score as one that failed 3 of the last 10. Recency weighting can be added in v2 if needed. The sliding window (always last N runs) naturally ages out old data as new runs arrive.

---

## Decision 7: History Store Interface Design — Extend vs. New Interface

**Rationale**: The existing `Store` interface (`packages/core/src/store.ts`) handles `TestRecord`, `BuildRecord`, and `ActivityRecord` with Memory and File implementations. For the history feature, we need a new `HistoryStore` interface because: (1) the data model is fundamentally different (run-level + case-level with relationships), (2) SQLite requires different access patterns than JSON files, (3) the existing `Store` serves a different purpose (session-scoped operational data vs. persistent historical analytics).

The `HistoryStore` will be a separate interface in `packages/core/src/history/` with its own SQLite implementation, MemoryStore (for tests), and factory function. It follows the same factory pattern as the existing `createStore()`.

**Alternatives considered**:

| Option | Pros | Cons |
|--------|------|------|
| **New HistoryStore interface (chosen)** | Clean separation, purpose-built for analytics | New interface to maintain |
| **Extend existing Store** | Single interface | Bloated interface, SQLite doesn't fit Memory/File patterns |
| **Repository pattern** | DDD-clean | Over-engineered for a dev tool |

**Trade-offs**: Two store interfaces in core. Acceptable because they serve different concerns: `Store` = operational (session state), `HistoryStore` = analytical (historical trends).

---

## Decision 8: Write Serialization — Application-Level Queue

**Rationale**: FR-018 requires serialized writes. better-sqlite3 is synchronous, so within a single process, writes are already serialized. For the edge case of concurrent MCP + Dashboard triggers, we use a simple async write queue (a `Promise` chain) to ensure only one write operation executes at a time. This avoids `SQLITE_BUSY` errors without relying on busy_timeout alone.

**Implementation**: A lightweight `WriteQueue` class wrapping an internal `Promise` chain. Each write operation is enqueued and awaits the previous one.

---

## Decision 9: Trigger Source Detection — Injection at Call Site

**Rationale**: FR-003 requires recording whether a test was triggered from CLI, MCP, Dashboard, or CI. Rather than auto-detecting (fragile), each call site passes a `triggerSource` parameter. MCP tools pass `'mcp'`, CLI commands pass `'cli'`, Dashboard routes pass `'dashboard'`, and CI is detected via `process.env.CI`.

**Pattern**:

```typescript
type TriggerSource = 'cli' | 'mcp' | 'dashboard' | 'ci';

function detectTriggerSource(explicit?: TriggerSource): TriggerSource {
  if (explicit) return explicit;
  if (process.env.CI) return 'ci';
  return 'cli'; // default fallback
}
```

---

## Decision 10: Retention Cleanup — On-Write Pruning

**Rationale**: FR-015 requires automatic retention enforcement (default 90 days, max 1000 runs). Rather than a background scheduler (which adds complexity for a CLI tool), cleanup runs as a post-write step after each `saveRun()`. This is efficient because: (1) SQLite DELETE with indexed timestamp is O(log n), (2) it happens at most once per test run, (3) it keeps the system stateless (no timers).

**Pattern**:

```sql
-- After inserting a new run:
DELETE FROM test_runs WHERE project = ? AND timestamp < ?;  -- time-based
DELETE FROM test_runs WHERE project = ? AND id NOT IN (
  SELECT id FROM test_runs WHERE project = ? ORDER BY timestamp DESC LIMIT ?
);  -- count-based
```

Cascade delete on `test_case_runs` (via `ON DELETE CASCADE`) ensures case records are cleaned up automatically.
